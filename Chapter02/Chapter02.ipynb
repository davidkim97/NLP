{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6tR33fK1V_dx"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RtyzDRZKYylX"},"outputs":[],"source":["with open('/gdrive/My Drive/test.txt', 'w') as f:\n","    f.writelines(\"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NfAX59VlY8AX"},"outputs":[],"source":["!pip install ratsnlp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XwQbTPeWLegd"},"outputs":[],"source":["# 코포라를 활용해 BPE 수행 대상 말뭉치를 내려받고 전처리\n","# 데이터는 네이버 영화 리뷰 NSMC\n","from Korpora import Korpora\n","nsmc = Korpora.load(\"nsmc\", force_download=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NJgIVCF3Lzid"},"outputs":[],"source":["# NSMC 전처리\n","# NSMC에 포함된 영화 리뷰를 순수 텍스트 형태로 저장\n","import os\n","def write_lines(path, lines):\n","    with open(path, 'w', encoding='utf-8') as f:\n","        for line in lines:\n","            f.write(f'{line}\\n')\n","\n","write_lines(\"/content/train.txt\", nsmc.train.get_all_texts())\n","write_lines(\"/content/test.txt\", nsmc.test.get_all_texts())"]},{"cell_type":"markdown","metadata":{"id":"-QEZG043M5sy"},"source":["### GPT 토크나이저 구축\n","- 문자 단위가 아닌 유니코드 바이트 수준으로 어휘 집합을 구축하고 토큰화를 수행\n","- 바이트 수준으로 BPE를 수행한다는 것은 어휘 집합 구축 대상 말뭉치를 위와 같이 변환, 이것을 문자 취급해 가장 자주 ㄷㅇ장한 문자열을 병합하는 방식으로 어휘 집합 생성."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdx4uV9eNYgI"},"outputs":[],"source":["# 디렉토리 생성\n","import os\n","os.makedirs(\"/gdrive/My Drive/nlpbook/bbpe\", exist_ok = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZF9kEiUeN8M9"},"outputs":[],"source":["# 바이트 수준 BPE 어휘 집합 구축\n","from tokenizers import ByteLevelBPETokenizer\n","bytebpe_tokenizer = ByteLevelBPETokenizer()\n","bytebpe_tokenizer.train(\n","    files=[\"/content/train.txt\", \"/content/test.txt\"],\n","    vocab_size=10000,\n","    special_tokens=[\"[PAD]\"]\n",")\n","bytebpe_tokenizer.save_model(\"/gdrive/My Drive/nlpbook/bbpe\")"]},{"cell_type":"markdown","metadata":{"id":"dGUS5-6LgNpy"},"source":["### BERT 토크나이저 구축\n","- BERT는 워드피스 토크나이저 사용"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GDNBMdKDgW2Q"},"outputs":[],"source":["os.makedirs(\"/gdrive/My Drive/nlpbook/wordpiece\", exist_ok = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MeBcaOzpgmhA"},"outputs":[],"source":["# 워드피스 어휘 집합 구축\n","from tokenizers import BertWordPieceTokenizer\n","\n","wordpiece_tokenizer = BertWordPieceTokenizer()\n","wordpiece_tokenizer.train(\n","    files = [\"/content/train.txt\", \"/content/test.txt\"],\n","    vocab_size = 10000,\n",")\n","\n","wordpiece_tokenizer.save_model(\"/gdrive/My Drive/nlpbook/wordpiece\")"]},{"cell_type":"markdown","metadata":{"id":"zzy9BnFt2huX"},"source":["### 토큰화"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S0pRnTCv2lXZ"},"outputs":[],"source":["# GPT 토크나이저 선언\n","from transformers import GPT2Tokenizer\n","\n","tokenizer_gpt = GPT2Tokenizer.from_pretrained(\"/gdrive/My Drive/nlpbook/bbpe\")\n","tokenizer_gpt.pad_token = \"[PAD]\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3nyiRvDA3Jiq"},"outputs":[],"source":["# GPT 토크나이저로 토큰화 하기\n","sentences = [\n","    \"아 더빙.. 진짜 짜증나네요 목소리\",\n","    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n","    \"별루 였다..\",\n","]\n","\n","tokenizer_sentences = [tokenizer_gpt.tokenize(sentence) for sentence in sentences]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZV_AIKG83jw6"},"outputs":[],"source":["tokenizer_sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"32QFTnLL3o8R"},"outputs":[],"source":["# GPT 모델 입력 만들기\n","sentences = [\n","    \"아 더빙.. 진짜 짜증나네요 목소리\",\n","    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n","    \"별루 였다..\",\n","]\n","batch_inputs = tokenizer_gpt(\n","    sentences,\n","    padding=\"max_length\",\n","    max_length=12,\n","    truncation=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOABI1Qx4Z86"},"outputs":[],"source":["# BERT 입력값 만들기\n","from transformers import BertTokenizer\n","\n","tokenizer_bert = BertTokenizer.from_pretrained(\n","    \"/gdrive/My Drive/nlpbook/wordpiece\",\n","    do_lower_case = False,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mM-lOnml5t5A"},"outputs":[],"source":["# BERT 토크나이저로 토큰화하기\n","sentences = [\n","    \"아 더빙.. 진짜 짜증나네요 목소리\",\n","    \"흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\",\n","    \"별루 였다..\",\n","]\n","\n","tokenized_sentences = [tokenizer_bert.tokenize(sentence) for sentence in sentences]\n","\n","tokenized_sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vt5ExGYp6Qfr"},"outputs":[],"source":["# BERT 모델 입력 만들기\n","batch_inputs = tokenizer_bert(\n","    sentences,\n","    padding=\"max_length\",\n","    max_length=12,\n","    truncation=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GH4nksZi6sSi"},"outputs":[],"source":["batch_inputs['input_ids']"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP63PXVW5zw0zFlwHzDy3RZ","private_outputs":true,"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.13 ('newenv')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.13"},"vscode":{"interpreter":{"hash":"04a6e8c298614e388494feb61c71b7f93a89f32600f7755021bbfd4894d72710"}}},"nbformat":4,"nbformat_minor":0}
